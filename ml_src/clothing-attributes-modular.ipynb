{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Procesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocessing import train_valid_test_split, combine_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOURCE_DATA_DIR = \"data/ClothingAttributeDataset/images/\"\n",
    "TARGET_DATA_DIR = \"data/ClothingAttributeDataset/\"\n",
    "\n",
    "train_valid_test_split(SOURCE_DATA_DIR, TARGET_DATA_DIR, train_size=0.8, valid_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1484\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/ClothingAttributeDataset/train | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/ClothingAttributeDataset/valid | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LABEL_DIR = \"data/ClothingAttributeDataset/labels/\"\n",
    "LABELS_FILE = \"data/ClothingAttributeDataset/labels.csv\"\n",
    "\n",
    "labels_df = combine_labels(LABEL_DIR, LABELS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern_cols = [col for col in labels_df.columns if \"pattern_\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pattern_spot_GT       NaN\n",
       "pattern_solid_GT      NaN\n",
       "pattern_graphics_GT   NaN\n",
       "pattern_plaid_GT      NaN\n",
       "pattern_stripe_GT     NaN\n",
       "pattern_floral_GT     NaN\n",
       "Name: 000021.jpg, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.ix[\"000021.jpg\", pattern_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# binary_columns = ['skin_exposure_GT', 'collar_GT', 'gender_GT', 'scarf_GT', 'necktie_GT',  'placket_GT']\n",
    "# multi_columns = ['category_GT', 'neckline_GT', 'sleevelength_GT']\n",
    "    \n",
    "# color_columns = ['white_GT', 'yellow_GT', 'gray_GT', 'green_GT', 'blue_GT', 'brown_GT', 'red_GT',\n",
    "#                  'cyan_GT', 'black_GT', 'purple_GT', 'many_colors_GT']\n",
    "# pattern_columns = ['pattern_spot_GT', 'pattern_solid_GT', 'pattern_graphics_GT', \n",
    "#                   'pattern_plaid_GT', 'pattern_stripe_GT', 'pattern_floral_GT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_df[\"pattern_GT\"] = labels_df[pattern_cols].apply(lambda row: row.argmax(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"label_values.json\", 'r') as f:\n",
    "    label_values = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category_GT': {'0': 'Shirt',\n",
       "  '1': 'Sweater',\n",
       "  '2': 'T-shirt',\n",
       "  '3': 'Outerwear',\n",
       "  '4': 'Suit',\n",
       "  '5': 'Tank Top',\n",
       "  '6': 'Dress'},\n",
       " 'neckline_GT': {'0': 'V-shape', '1': 'Round', '2': 'Other shapes'},\n",
       " 'pattern_GT': {'0': 'Floral',\n",
       "  '1': 'Graphics',\n",
       "  '2': 'Plaid',\n",
       "  '3': 'Stripe',\n",
       "  '4': 'Solid',\n",
       "  '5': 'Spot'},\n",
       " 'sleevelength_GT': {'0': 'No sleeves',\n",
       "  '1': 'Short sleeves',\n",
       "  '2': 'Long sleeves'}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values_to_idx = {\n",
    "    \"pattern_GT\": {  \n",
    "        \"pattern_floral_GT\": 0,\n",
    "        \"pattern_graphics_GT\": 1,\n",
    "        \"pattern_plaid_GT\": 2,\n",
    "        \"pattern_stripe_GT\": 3,\n",
    "        \"pattern_solid_GT\": 4,\n",
    "        \"pattern_spot_GT\": 5\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image\n",
       "000001.jpg    1\n",
       "000002.jpg    5\n",
       "000003.jpg    4\n",
       "000004.jpg    4\n",
       "000005.jpg    4\n",
       "000006.jpg    4\n",
       "000007.jpg    4\n",
       "000008.jpg    4\n",
       "000009.jpg    5\n",
       "000010.jpg    4\n",
       "000011.jpg    4\n",
       "000012.jpg    4\n",
       "000013.jpg    4\n",
       "000014.jpg    4\n",
       "000015.jpg    0\n",
       "000016.jpg    4\n",
       "000017.jpg    4\n",
       "000018.jpg    4\n",
       "000019.jpg    4\n",
       "000020.jpg    4\n",
       "000022.jpg    5\n",
       "000023.jpg    3\n",
       "000024.jpg    5\n",
       "000025.jpg    4\n",
       "000026.jpg    4\n",
       "000027.jpg    0\n",
       "000028.jpg    5\n",
       "000029.jpg    4\n",
       "000030.jpg    4\n",
       "000031.jpg    4\n",
       "             ..\n",
       "001827.jpg    2\n",
       "001828.jpg    2\n",
       "001829.jpg    2\n",
       "001830.jpg    2\n",
       "001831.jpg    2\n",
       "001832.jpg    2\n",
       "001833.jpg    2\n",
       "001834.jpg    2\n",
       "001835.jpg    2\n",
       "001836.jpg    2\n",
       "001837.jpg    2\n",
       "001838.jpg    2\n",
       "001839.jpg    2\n",
       "001840.jpg    2\n",
       "001841.jpg    2\n",
       "001842.jpg    2\n",
       "001843.jpg    2\n",
       "001844.jpg    2\n",
       "001845.jpg    2\n",
       "001846.jpg    2\n",
       "001847.jpg    2\n",
       "001848.jpg    2\n",
       "001849.jpg    2\n",
       "001850.jpg    2\n",
       "001851.jpg    2\n",
       "001852.jpg    2\n",
       "001853.jpg    2\n",
       "001854.jpg    2\n",
       "001855.jpg    2\n",
       "001856.jpg    2\n",
       "Name: pattern_GT, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.loc[mask, \"pattern_GT\"].map(values_to_idx[\"pattern_GT\"], na_action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-035c53a1e63b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-035c53a1e63b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    labels_df.loc[mask, \"pattern_GT\"] =  labels_df.loc[mask, \"pattern_GT\"],.map()\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mask = (~pd.isnull(labels_df[\"pattern_GT\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from classifiers import get_pretrained_model, create_attributes_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_IMAGES_FOLDER = \"data/ClothingAttributeDataset/train/\"\n",
    "VALID_IMAGES_FOLDER = \"data/ClothingAttributeDataset/valid/\"\n",
    "LABELS_FILE = \"data/ClothingAttributeDataset/labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_COLUMNS = {\n",
    "    \"category_GT\": 7,\n",
    "    \"sleevelength_GT\": 3,\n",
    "    \"neckline_GT\": 3\n",
    "}\n",
    "\n",
    "#     \"pattern_GT\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pretrained_features, pretrained_fc, fc_dim = get_pretrained_model(\"alexnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "LR is set to 0.001\n",
      "train Loss: 0.0283 Acc: 0.6517\n",
      "valid Loss: 0.0292 Acc: 0.6805\n",
      "Training completed in 0.000000m 4.595832s\n",
      "Best val Acc: 0.680451\n",
      "Epoch 0/0\n",
      "LR is set to 0.001\n",
      "train Loss: 0.0493 Acc: 0.6112\n",
      "valid Loss: 0.0496 Acc: 0.6402\n",
      "Training completed in 0.000000m 4.024902s\n",
      "Best val Acc: 0.640187\n",
      "Epoch 0/0\n",
      "LR is set to 0.001\n",
      "train Loss: 0.0226 Acc: 0.8382\n",
      "valid Loss: 0.0230 Acc: 0.8525\n",
      "Training completed in 0.000000m 6.417231s\n",
      "Best val Acc: 0.852459\n"
     ]
    }
   ],
   "source": [
    "models = create_attributes_model(pretrained_features, pretrained_fc, fc_dim, TARGET_COLUMNS, \"weights/\",\n",
    "                                LABELS_FILE, TRAIN_IMAGES_FOLDER, VALID_IMAGES_FOLDER, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category_GT': AttributeModel (\n",
       "   (model): Sequential (\n",
       "     (0): Dropout (p = 0.5)\n",
       "     (1): Linear (9216 -> 4096)\n",
       "     (2): ReLU (inplace)\n",
       "     (3): Dropout (p = 0.5)\n",
       "     (4): Linear (4096 -> 4096)\n",
       "     (5): ReLU (inplace)\n",
       "     (6): Linear (4096 -> 7)\n",
       "   )\n",
       " ), 'neckline_GT': AttributeModel (\n",
       "   (model): Sequential (\n",
       "     (0): Dropout (p = 0.5)\n",
       "     (1): Linear (9216 -> 4096)\n",
       "     (2): ReLU (inplace)\n",
       "     (3): Dropout (p = 0.5)\n",
       "     (4): Linear (4096 -> 4096)\n",
       "     (5): ReLU (inplace)\n",
       "     (6): Linear (4096 -> 3)\n",
       "   )\n",
       " ), 'sleevelength_GT': AttributeModel (\n",
       "   (model): Sequential (\n",
       "     (0): Dropout (p = 0.5)\n",
       "     (1): Linear (9216 -> 4096)\n",
       "     (2): ReLU (inplace)\n",
       "     (3): Dropout (p = 0.5)\n",
       "     (4): Linear (4096 -> 4096)\n",
       "     (5): ReLU (inplace)\n",
       "     (6): Linear (4096 -> 3)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1321832\r\n",
      "drwxrwxr-x 2 paperspace paperspace      4096 Mar 30 01:15 .\r\n",
      "drwxrwxr-x 7 paperspace paperspace      4096 Mar 30 09:35 ..\r\n",
      "-rw-rw-r-- 1 paperspace paperspace 218252204 Mar 30 09:35 category_GT.path\r\n",
      "-rw-rw-r-- 1 paperspace paperspace 218252194 Mar 29 23:49 example.pth\r\n",
      "-rw-rw-r-- 1 paperspace paperspace 218186652 Mar 30 09:35 neckline_GT.path\r\n",
      "-rw-rw-r-- 1 paperspace paperspace 218186656 Mar 30 09:36 sleevelength_GT.path\r\n",
      "-rw-rw-r-- 1 paperspace paperspace 218252194 Mar 30 00:27 sleevelength_GT.pth\r\n",
      "-rw-rw-r-- 1 paperspace paperspace 262392552 Mar 23 18:10 slevelength_1.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
